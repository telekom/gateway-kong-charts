# SPDX-FileCopyrightText: 2023 Deutsche Telekom AG
#
# SPDX-License-Identifier: Apache-2.0

global:
  metadata:
    pipeline: {}

  #pathToSecret: "path/to/secret" 

  # -- Storage class name for PVCs (defaults to cluster default storage class if not set)
  #storageClassName: ""
  #environment: ""
  zone: "zoneName"
  # -- Define global labels
  labels:
    # fluentd label
    tardis.telekom.de/group: tardis
  product: "stargate"
  ingress:
    # -- Default ingress class name for all ingress resources (can be overridden per-ingress)
    # If not set, uses cluster default ingress class
    #ingressClassName: ""
    # -- Set annotations for all ingress, can be extended by ingress specific ones
    annotations: {}
      #external-dns.alpha.kubernetes.io/target: ""
      #kubernetes.io/ingress.class: ""

  # Default registry and namespace for all images
  # Can be overridden per component (e.g., image.registry, jumper.image.registry)
  # 
  # Images are constructed as: {registry}/{namespace}/{repository}:{tag}
  # Example: mtr.devops.telekom.de/eu_it_co_development/o28m/gateway-kong:1.1.0
  image:
    # -- Default registry for all images
    registry: mtr.devops.telekom.de
    # -- Default namespace for all images
    namespace: eu_it_co_development/o28m

  # If imagePullSecrets is not empty, a pull secret will be deployed for each entry otherwise 
  # no pull secret will be deployed
  # If you use Sapling for deployment this will be set automatically
  # -- array of pull secret names to use for image pulling
  imagePullSecrets: 

  # -- global default for imagePullPolicy
  imagePullPolicy: IfNotPresent

  passwordRules:
    enabled: false
    length: 12
    mustMatch:
    - '[a-z]'
    - '[A-Z]'
    - '[0-9]'
    - '[^a-zA-Z0-9]'

  database:
    # -- Determine if the a database will be deployed togehter with Stargate (local) or is provided (external)
    location: local
    # -- Port of the database
    port: 5432
    # -- Name of the database
    database: kong
    # -- Name of the schema
    schema: public
    # -- Username for accessing the database
    username: kong
    # -- The users password
    password: changeme

  # Set a global collectorUrl for traces.
  # Can be overwritten by individual settings
  tracing:
    # -- URL of the Zipkin-Collector (e.g. Jaeger-Collector), http(s) mandatory
    collectorUrl: "http://guardians-drax-collector.skoll:9411/api/v2/spans"
    # -- Name of the service shown in e.g. Jaeger
    defaultServiceName: "stargate"
    # -- How often to sample requests that do not contain trace ids. Set to 0 to turn sampling off, or to 1 to sample all requests.
    sampleRatio: 1

  podAntiAffinity:
    # -- configure pod anti affinity to be requiredDuringSchedulingIgnoredDuringExecution or preferredDuringSchedulingIgnoredDuringExecution
    required: false

  # -- 
  failOnUnsetValues: true

  preStopSleepBase: 30

# You can list files (in /templates) here that should cause a re-deployment of your application
# when their contents change
# This makes sense if you change configMaps or secrets and you
# want your deployment to use the latest configuration
#
#templateChangeTriggers:
#- my-custom-configmap.yaml
# -- List of (template) yaml files fo which a checksum annotation will be created
templateChangeTriggers: []

# -- Kong Gateway image configuration (inherits global.image.registry and global.image.namespace)
image:
  # registry: ""  # Uncomment to override global.image.registry
  # namespace: ""  # Uncomment to override global.image.namespace
  repository: gateway-kong
  tag: "1.2.1"

# -- Image pull policy for Kong container
imagePullPolicy: IfNotPresent

# Determine the migrations behaviour (bootstrap, upgrade, jobs)
# bootstrap: setting up a new deployments database
# upgrade: utilizing Kongs upgrade task for e.g. database migrations
# jobs: migrating from eni-plugins to ENI flavoured original plugins
# Comment out or set to none if none of the options are needed
# -- Determine the migrations behaviour for a new instance or upgrade
migrations: none


# Enable Admin API and whether it is http or https
# Warning: 
adminApi:
  # -- Create service for accessing Kong Admin API
  enabled: true
  gatewayAdminApiKey: changeme
  htpasswd: admin:changeme
  tls:
    # -- Access Admin API via https instead of http  
    enabled: false
  # -- Set the log target for access log
  accessLog: /dev/stdout
  # -- Set the log target for error log
  errorLog: /dev/stderr
# Activate Admin API ingress and set a dedicated hostname
# For EE (license) this is default true, for CE (no license) this is default false
  ingress:
    # -- Create ingress for Admin API. Default depends on Edition (CE: false, EE: true)
    enabled: true
    # -- Set ingress className for the Admin API ingress (overrides global.ingress.ingressClassName)
    #className: ""
    # -- Merges specific into global ingress annotations
    annotations: {}
    # -- Set usual ingress array of hosts
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: Prefix
    tls: []
      # secretName is optional as for example in aws for a loadbalancer ingress this is not needed
      #- secretName: secretName
      #  hosts:
      #    - hostNameMatchingCertInSecret


# Activate proxy ingress and set a dedicated hostname
proxy:
  tls:
    enabled: false
  # -- Set the log target for access log
  accessLog: /dev/stdout
  # -- Set the log target for error log
  errorLog: /dev/stderr
  ingress:
    # -- Create ingress for proxy
    enabled: true
    # -- Set ingressClassName for the proxy ingress (overrides global.ingress.ingressClassName)
    #className: ""
    # -- Merges specific into global ingress annotations
    annotations: {}
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: Prefix
    tls: []
      # secretName is optional as for example in aws for a loadbalancer ingress this is not needed
      #- secretName: secretName
      #  hosts:
      #    - hostNameMatchingCertInSecret

# -- Set a script to run after deployment for configuration of the Gateway
#configuration: |
  #Place your curl commands here to configure via Admin-API on deploy time

# values used by nginx directives
# -- Controls whether to check forward proxy traffic against CA certificates
sslVerify: false
# -- SSL Verification depth
sslVerifyDepth: '1'

# You can define the truststore for SSL verification by setting your CAs in PEM format here 
#
# -- CA certificates in PEM format (string)
#trustedCaCertificates: |
#  -----BEGIN CERTIFICATE-----
#  <CA certificate 01 in PEM format here>
#  -----END CERTIFICATE-----
#  -----BEGIN CERTIFICATE-----
#  <CA certificate 02 in PEM format here>
#  -----END CERTIFICATE-----
#  -----BEGIN CERTIFICATE-----
#  <CA certificate 03 in PEM format here>
#  -----END CERTIFICATE-----

# You can define the default HTTPS server certificate by specifing the secret with private-key/certificate here
# Note: additional route-specific server certificates can by configured and assigned to SNIs at runtime. This is only a default certificate
# -- Name of the secret containing the default server certificates
#defaultTlsSecret: "mysecret"

ssl:
  protocols: "TLSv1.2 TLSv1.3"
# Defines the TLS ciphers served by Nginx.
# Accepted values are modern, intermediate, old, or custom.
# See https://wiki.mozilla.org/Security/Server_Side_TLS for detailed descriptions of each cipher suite.
  cipherSuite: "custom"

#Defines a custom list of TLS ciphers to be served by Nginx. This list must conform to the pattern defined by openssl ciphers.
#This value is ignored if ssl_cipher_suite is not custom.
  ciphers: "DHE-DSS-AES128-SHA256:DHE-DSS-AES256-SHA256:DHE-DSS-AES128-GCM-SHA256:DHE-DSS-AES256-GCM-SHA384:DHE-RSA-AES128-CCM:DHE-RSA-AES256-CCM:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-CCM:ECDHE-ECDSA-AES256-CCM:ECDHE-ECDSA-AES128-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-CHACHA20-POLY1305:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:TLS_AES_128_CCM_SHA256"

disableUpstreamCache: false

# -- Pod security context for Kong deployment (hardened defaults)
podSecurityContext:
  runAsUser: 100
  runAsGroup: 1000
  fsGroup: 1000
  supplementalGroups: [1000]

# -- Container security context for Kong container (hardened defaults)
containerSecurityContext:
  runAsUser: 100
  runAsGroup: 1000
  runAsNonRoot: true
  readOnlyRootFilesystem: true
  allowPrivilegeEscalation: false
  privileged: false
  capabilities:
    drop:
    - ALL

# -- Topology key for pod anti-affinity (spread pods across zones for high availability)
topologyKey: kubernetes.io/hostname

# -- Job container security context
jobs:
  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL

# -- Kong memory cache size for database entities
memCacheSize: 128m
# -- Number of nginx worker processes
nginxWorkerProcesses: 4
# -- Nginx HTTP Lua shared dictionary for storing metrics
nginxHttpLuaSharedDict: "prometheus_metrics 15m"
# -- Nginx large client header buffers configuration
#nginxLargeClientBuffers: "8 16k"
# -- Kong worker consistency mode (eventual or strict)
workerConsistency: eventual
# -- Frequency in seconds to poll for worker state updates
workerStateUpdateFrequency: 10
# -- Frequency in seconds to poll database for updates
dbUpdateFrequency: 10
# -- Delay in seconds before propagating database updates
dbUpdatePropagation: 0
# -- HTTP client body buffer size (optional override)
#httpClientBodyBufferSize: 4m
# -- Trusted IPs for real IP detection (optional override)
#trustedIps: 100.70.0.0/16
# -- Header to use for real IP detection (optional override)
#realIpHeader: x-original-forwarded-for
# -- Whether to recursively search for client IP (optional override)
#realIpRecursive: OFF

# -- Number of Kong pod replicas (ignored when HPA, KEDA, or Argo Rollouts is enabled)
replicas: 1

# -- Deployment strategy configuration
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 25%
    maxSurge: 25%

# -- Horizontal Pod Autoscaler configuration
hpaAutoscaling:
  enabled: false
  # -- Minimum number of replicas
  minReplicas: 3
  # -- Maximum number of replicas
  maxReplicas: 10
  # -- Target CPU utilization percentage
  cpuUtilizationPercentage: 80

# ============================================================================
# KEDA-Based Autoscaling Configuration
# ============================================================================
# KEDA (Kubernetes Event-Driven Autoscaling) provides advanced autoscaling
# capabilities including custom metrics, schedule-based scaling, and
# sophisticated anti-flapping protection.
#
# Prerequisites:
# - KEDA must be installed in the cluster (helm install keda kedacore/keda)
# - Victoria Metrics must be accessible for custom metric scaling
# - Kubernetes metrics server must be running for CPU/memory scaling
#
# Note: kedaAutoscaling and autoscaling (HPA) are mutually exclusive.
# Enable only one at a time.
# ============================================================================

kedaAutoscaling:
  # -- Enable KEDA-based autoscaling (disables standard HPA if enabled)
  enabled: false
  
  # ============================================================================
  # Replica Boundaries
  # ============================================================================
  
  # -- Minimum number of replicas (must be >= 1)
  minReplicas: 2
  
  # -- Maximum number of replicas (must be >= minReplicas)
  maxReplicas: 10
  
  # ============================================================================
  # Timing Configuration (Anti-Flapping)
  # ============================================================================
  
  # -- Polling interval in seconds (how often KEDA checks metrics)
  # Lower values = more responsive but more API calls
  # Recommended: 30-60 seconds for balanced behavior
  pollingInterval: 30
  
  # -- Cooldown period in seconds (minimum time between scale-down actions)
  # Prevents rapid scale-down oscillations
  # Recommended: 300 seconds (5 minutes) for stable workloads
  cooldownPeriod: 300
  
  # ============================================================================
  # Fallback Configuration
  # ============================================================================
  # Defines behavior when all scaling triggers fail (e.g., metrics unavailable)
  
  fallback:
    # -- Enable fallback to a fixed replica count when all triggers fail
    enabled: false
    
    # -- Number of replicas to maintain when all triggers fail (e.g. maxReplicas)
    replicas: 10
  
  # ============================================================================
  # Advanced HPA Behavior Configuration
  # ============================================================================
  # Fine-tune scaling behavior using Kubernetes HPA v2 behavior policies
  
  advanced:
    # -- Restore to original replica count when ScaledObject is deleted
    restoreToOriginalReplicaCount: false
    
    # -- HPA behavior configuration (scale-up/scale-down policies)
    horizontalPodAutoscalerConfig:
      behavior:
        # Scale-down behavior (conservative to prevent flapping)
        scaleDown:
          # -- Stabilization window for scale-down (seconds)
          # KEDA waits this long before scaling down to ensure load is sustained
          stabilizationWindowSeconds: 300
          
          # -- Scale-down policies (multiple policies can be defined)
          policies:
          - type: Percent
            value: 10        # Max 10% reduction per period
            periodSeconds: 60
          
          # -- Policy selection (Min = most conservative, Max = most aggressive)
          selectPolicy: Min
        
        # Scale-up behavior (aggressive for availability)
        scaleUp:
          # -- Stabilization window for scale-up (seconds)
          # 0 = immediate scale-up for availability
          stabilizationWindowSeconds: 0
          
          # -- Scale-up policies
          policies:
          - type: Percent
            value: 100       # Max 100% increase per period
            periodSeconds: 60
          - type: Pods
            value: 4         # Or max 4 pods per period
            periodSeconds: 60
          
          # -- Policy selection (Max = use most aggressive policy)
          selectPolicy: Max
  
  # ============================================================================
  # Scaling Triggers
  # ============================================================================
  # Multiple triggers can be enabled simultaneously (OR logic)
  # If ANY trigger suggests scale-up → scale up
  # If ALL triggers suggest scale-down → scale down (after cooldown)
  
  triggers:
    
    # ==========================================================================
    # CPU Resource Scalers (Per-Container)
    # ==========================================================================
    # Scales based on CPU utilization percentage for individual containers
    # Requires: Kubernetes metrics server
    # Multiple containers can be monitored independently
    
    cpu:
      # -- Enable CPU-based scaling for any container
      enabled: true
      
      # -- Per-container CPU thresholds
      # Each container in the pod can have its own threshold
      # If ANY container exceeds its threshold, scaling is triggered
      containers:
        # Kong container (main API gateway)
        kong:
          # -- Enable CPU monitoring for kong container
          enabled: true
          # -- CPU utilization threshold percentage (0-100)
          # Recommended: 60-80% for headroom
          threshold: 70
        
        # Jumper container (JWT validation service)
        jumper:
          # -- Enable CPU monitoring for jumper container
          enabled: true
          # -- CPU utilization threshold percentage (0-100)
          threshold: 70
        
        # Issuer Service container (certificate issuer)
        issuerService:
          # -- Enable CPU monitoring for issuer-service container
          enabled: true
          # -- CPU utilization threshold percentage (0-100)
          threshold: 70
    
    # ==========================================================================
    # Memory Resource Scalers (Per-Container)
    # ==========================================================================
    # Scales based on memory utilization percentage for individual containers
    # Requires: Kubernetes metrics server
    # Multiple containers can be monitored independently
    
    memory:
      # -- Enable memory-based scaling for any container
      enabled: true
      
      # -- Per-container memory thresholds
      # Each container in the pod can have its own threshold
      # If ANY container exceeds its threshold, scaling is triggered
      containers:
        # Kong container (main API gateway)
        kong:
          # -- Enable memory monitoring for kong container
          enabled: true
          # -- Memory utilization threshold percentage (0-100)
          # Recommended: 80-90% (higher than CPU due to less elasticity)
          threshold: 95
        
        # Jumper container (JWT validation service)
        jumper:
          # -- Enable memory monitoring for jumper container
          enabled: true
          # -- Memory utilization threshold percentage (0-100)
          threshold: 85
        
        # Issuer Service container (certificate issuer)
        issuerService:
          # -- Enable memory monitoring for issuer-service container
          enabled: true
          # -- Memory utilization threshold percentage (0-100)
          threshold: 85
    
    # ==========================================================================
    # Prometheus/Victoria Metrics Scaler
    # ==========================================================================
    # Scales based on custom metrics from Victoria Metrics
    # Requires: Victoria Metrics accessible, authentication configured
    
    prometheus:
      # -- Enable Prometheus/Victoria Metrics based scaling
      enabled: true
      
      # -- Victoria Metrics server address (REQUIRED if enabled)
      # Example: "http://prometheus.monitoring.svc.cluster.local:8427"
      # Can use template variables: "{{ .Values.global.vmauth.url }}"
      serverAddress: ""
      
      # -- Metric name (used for identification in KEDA)
      metricName: "kong_request_rate"
      
      # -- PromQL query to execute
      # Must return a single numeric value
      # Can use Helm template variables (e.g., {{ .Values.global.zone }})
      # Example queries:
      #   - Request rate: sum(rate(kong_http_requests_total{zone="zone1"}[1m]))
      #   - Error rate: sum(rate(kong_http_requests_total{status=~"5.."}[1m]))
      query: 'sum(rate(kong_http_requests_total{tardis_telekom_de_zone="{{ .Values.global.zone }}"}[1m]))'
      
      # -- Threshold value for the metric
      # Scales up when query result exceeds this value
      # For request rate: total requests/second across all pods
      threshold: "100"
      
      # -- Activation threshold (optional)
      # Minimum metric value to activate this scaler
      # Prevents scaling from 0 on minimal load
      activationThreshold: ""
      
      # -- Authentication mode for Victoria Metrics
      # Options: "basic", "bearer", "tls"
      authModes: "basic"
      
      # -- Authentication configuration
      # Reference to existing TriggerAuthentication or ClusterTriggerAuthentication resource
      # - ClusterTriggerAuthentication: cluster-scoped resource that can be shared across namespaces
      # - TriggerAuthentication: namespace-scoped resource (useful for namespace-restricted environments)
      authentication:
        # -- Authentication kind: "ClusterTriggerAuthentication" or "TriggerAuthentication"
        # Use "TriggerAuthentication" for namespace-scoped environments
        # Use "ClusterTriggerAuthentication" for cluster-wide shared credentials
        kind: "ClusterTriggerAuthentication"
        
        # -- Name of the TriggerAuthentication or ClusterTriggerAuthentication resource
        # This resource must be created separately and contain Victoria Metrics credentials
        # Example ClusterTriggerAuthentication:
        #   apiVersion: keda.sh/v1alpha1
        #   kind: ClusterTriggerAuthentication
        #   metadata:
        #     name: eni-keda-vmselect-creds
        #   spec:
        #     secretTargetRef:
        #     - parameter: username
        #       name: victoria-metrics-secret
        #       key: username
        #     - parameter: password
        #       name: victoria-metrics-secret
        #       key: password
        #
        # Example TriggerAuthentication (namespace-scoped):
        #   apiVersion: keda.sh/v1alpha1
        #   kind: TriggerAuthentication
        #   metadata:
        #     name: vmselect-creds
        #     namespace: my-namespace
        #   spec:
        #     secretTargetRef:
        #     - parameter: username
        #       name: victoria-metrics-secret
        #       key: username
        #     - parameter: password
        #       name: victoria-metrics-secret
        #       key: password
        name: "eni-keda-vmselect-creds"
    
    # ==========================================================================
    # Cron-Based Scalers
    # ==========================================================================
    # Scales based on time schedules (predictable traffic patterns)
    # Multiple schedules can be defined for different time windows
    
    cron:
      # -- Enable cron-based (schedule) scaling
      enabled: false
      
      # -- Timezone for cron schedules
      # Use IANA timezone database names for automatic DST handling
      # Europe/Berlin automatically handles CET (UTC+1) and CEST (UTC+2) transitions
      # Format: IANA timezone (e.g., "Europe/Berlin", "America/New_York", "Asia/Tokyo")
      # See: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
      timezone: "Europe/Berlin"
      
      # -- List of cron schedules
      # Each schedule defines a time window and desired replica count
      # Multiple schedules can overlap (highest desiredReplicas wins)
      schedules: []
      # Example schedules:
      # - name: "business-hours-scale-up"
      #   start: "0 8 * * 1-5"      # 8 AM Monday-Friday
      #   end: "0 18 * * 1-5"       # 6 PM Monday-Friday
      #   desiredReplicas: 5
      # 
      # - name: "weekend-scale-down"
      #   start: "0 0 * * 6-7"      # Midnight Saturday-Sunday
      #   end: "0 23 * * 6-7"       # 11 PM Saturday-Sunday
      #   desiredReplicas: 2
      #
      # - name: "night-scale-down"
      #   start: "0 22 * * *"       # 10 PM every day
      #   end: "0 6 * * *"          # 6 AM every day
      #   desiredReplicas: 2
      #
      # Cron expression format:
      # ┌───────────── minute (0 - 59)
      # │ ┌───────────── hour (0 - 23)
      # │ │ ┌───────────── day of month (1 - 31)
      # │ │ │ ┌───────────── month (1 - 12)
      # │ │ │ │ ┌───────────── day of week (0 - 6) (Sunday to Saturday)
      # │ │ │ │ │
      # * * * * *

resources:
  limits:
    cpu: 2500m
    memory: 4Gi
  requests:
    cpu: 1
    memory: 2Gi

# log_format select the pre-configured log formats for nginx
# It can have one of the values: default, json or plain.
# Formats: debug, default, json
logFormat: json

# -- kong livenessProbe configuration
livenessProbe:
  httpGet:
    path: /status
    port: status
    scheme: HTTP
  timeoutSeconds: 5
  periodSeconds: 20
  failureThreshold: 4
# -- kong readinessProbe configuration
readinessProbe:
  httpGet:
    path: /status
    port: status
    scheme: HTTP
  timeoutSeconds: 2
# -- kong startupProbe configuration
startupProbe:
  httpGet:
    path: /status
    port: status
    scheme: HTTP
  initialDelaySeconds: 5
  timeoutSeconds: 1
  periodSeconds: 1
  failureThreshold: 295

setupJobs:
  # -- How often should be retried to run the job successfully
  backoffLimit: 15
  # -- How long (in seconds) should be retried to run the job successfully
  activeDeadlineSeconds: 3600
  # -- resource defaults configured for the setupJobs
  resources:
    limits:
      cpu: 0.5
      memory: 500Mi
    requests:
      cpu: 50m
      memory: 200Mi
  # -- Container security context for setup jobs
  containerSecurityContext:
    runAsUser: 100
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL

plugins:
  # -- Container security context for plugin containers
  containerSecurityContext:
    runAsUser: 100
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL
  # -- additional enabled plugins for kong besides `bundled,jwt-keycloak`
  enabled:
    - rate-limiting-merged

  acl:
    # -- pluginId for configuration in kong
    pluginId: bc823d55-83b5-4184-b03f-ce63cd3b75c7
      
  jwtKeycloak:
    # -- Activate or deactivate the jwt-keycloak plugin
    enabled: true
    # -- pluginId for configuration in kong
    pluginId: b864d58b-7183-4889-8b32-0b92d6c4d513
    # -- Set the Iris URL you want the Gateway to use for Admin API athentication
    allowedIss: 
      - https://changeme/auth/realms/default

  prometheus:
    # -- Controls whether to annotate pods with prometheus scraping information or not
    enabled: true
    # -- pluginId for configuration in kong
    pluginId: 3d232d3c-dc2b-4705-aa8d-4e07c4e0ff4c
    # -- Sets the port at which metrics can be accessed
    port: 9542
    # -- Sets the endpoint at which at which metrics can be accessed
    path: /metrics
    serviceMonitor:
      # -- Enables a servicemonitor which can be used by the prometheus operator to collect metrics
      enabled: true
      # -- default selector label (only label)
      selector: "guardians-raccoon"
      # -- HTTP scheme to use for scraping
      #scheme: http
      # -- Interval at which metrics should be scraped
      #interval: "15s"
      # -- Timeout after which the scrape of prometheus is ended
      #scrapeTimeout: "3s"
      # -- HonorLabels chooses the metric’s labels on collisions with target labels
      # honorLabels: true
    podMonitor:
      # -- Enables a podmonitor which can be used by the prometheus operator to collect metrics
      enabled: false
      # -- Default selector label for pod monitor
      selector: "guardians-raccoon"
      # -- HTTP scheme to use for scraping
      # scheme: http
      # -- Interval at which metrics should be scraped
      #interval: "15s"
      # -- Timeout after which the scrape of prometheus is ended
      #scrapeTimeout: "3s"
      # -- HonorLabels chooses the metric’s labels on collisions with target labels
      #honorLabels: true

  requestSizeLimiting:
    enabled: true
    # -- pluginId for configuration in kong
    pluginId: 1e199eee-f592-4afa-8371-6b61dcbd1904
    #Size in megabytes
    #allowedPayloadSize: 4

  requestTransformer:
    # -- pluginId for configuration in kong
    pluginId: e9fb4272-0aff-4208-9efa-6bfec5d9df53

  zipkin:
    # -- Enable tracing via ENI-Zipkin-Plugin
    enabled: true
    # -- pluginId for configuration in kong
    pluginId: e8ff1211-816f-4d93-9011-a4b194586073
    # -- URL of the Zipkin-Collector (e.g. Jaeger-Collector), http(s) mandatory (defaults to global.tracing.collectorUrl)
    #collectorUrl: "http://guardians-drax-collector.skoll:9411/api/v2/spans"
    # -- How often to sample requests that do not contain trace ids. Set to 0 to turn sampling off, or to 1 to sample all requests.
    #sampleRatio: 1
    #environment: null
    #zone: null
    #forceSample: true
    #headerType: "b3"
    # -- Should the credential of the currently authenticated consumer be included in metadata sent to the Zipkin server?
    #includeCredential: "true"
    # -- Name of the service shown in e.g. Jaeger
    #defaultServiceName: "stargate"
    # -- CA certificate for the Zipkin-Collector-URL
    #luaSslTrustedCertificate: |
    #  -----BEGIN CERTIFICATE-----
    #  <CA certificate in PEM format here>
    #  -----END CERTIFICATE-----
    # Set job retries and maximum runtime (default values preset)

# irixBrokerRoute is a route on spacegate proxing to irix-broker
irixBrokerRoute:
  enabled: false
  name: user-login
  # optional if not according to the usual host rules
  #host: integration.spacegate.telekom.de
  upstream:
    protocol: http
    service: irix-broker
    path: /auth/realms/eni-login
    port: 80
    # optional if upstream should be accessed by ingress
    #host: integration.spacegate.telekom.de
    # optional if upstream should be accessed as service but in another namespace
    #namespace: integration

# Jumper is a component needed for Gateway-to-Gateway
# communication
jumper:
  # -- enable deployment of jumper conatiner inside gateway pod
  enabled: true
  
  # -- Jumper image configuration (inherits global.image.registry and global.image.namespace)
  image:
    # registry: ""  # Uncomment to override global.image.registry
    # namespace: ""  # Uncomment to override global.image.namespace
    repository: gateway-jumper
    tag: "4.2.5"
  
  # -- Image pull policy for Jumper container
  imagePullPolicy: IfNotPresent
  
  # -- Port for Jumper container
  port: 8080
  
  issuerUrl: https://localhost:443
  #tracingUrl: http://guardians-drax-collector.skoll:9411
  #defaultServiceName: "stargate"
  stargateUrl: https://stargate-integration.test.dhei.telekom.de
  publishEventUrl: http://producer.integration:8080/v1/events
  jvmOpts: "-XX:MaxRAMPercentage=75.0 -Dreactor.netty.pool.leasingStrategy=lifo"
  #maxHttpHeaderSize: 16KB
  #fpaProxyHost
  #fpaProxyPort
  #fpaNonProxyHostsRegex
  # -- jumper livenessProbe configuration
  livenessProbe:
    httpGet:
      path: /actuator/health/liveness
      port: jumper
      scheme: HTTP
    timeoutSeconds: 5
    failureThreshold: 6
  # -- jumper readinessProbe configuration
  readinessProbe:
    httpGet:
      path: /actuator/health/readiness
      port: jumper
      scheme: HTTP
    initialDelaySeconds: 5
  # -- jumper startupProbe configuration
  startupProbe:
    httpGet:
      path: /actuator/health/readiness
      port: jumper
      scheme: HTTP
    initialDelaySeconds: 15
    periodSeconds: 1
    failureThreshold: 285

  # -- generic injection possibility for additional environment variables
  #- {name: foo, value: bar}
  environment: []

  # -- Container security context for Jumper
  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL
  zoneHealth:
    defaultHealth: true
    databaseHost: localhost
    databaseConnectionTimeout: 500
    databaseTimeout: 500
    databasePort: 6379
    databaseIndex: 2
    keyChannel: stargate-zone-status
    requestRate: 10000
    databaseSecretName: redis
    databaseSecretKey: redis-password
    enabled: false

  # This is the list of zones that are considered internet facing within the whole existing ecosystem.
  # e.g. [space, canis, aries]
  # An empty list means that the default internet facing zones as part of the Jumper application config will be used.
  # -- list of zones that are considered internet facing
  internetFacingZones: []

  # When providing an existing secret, it has to compatible with a gateway-rotator managed one
  # Format is specified here https://github.com/telekom/gateway-rotator?tab=readme-ov-file#key-rotation-process
  # -- configure manually externally managed secret for oauth access token issueing (as alternative for keyRotation.enabled=true) 
  existingJwkSecretName:

  # -- jumper container default resource configuration
  resources:
    limits:
      cpu: 5
      memory: 1500Mi
    requests:
      cpu: 2
      memory: 1Gi

issuerService:
  # -- enable deployment of issuer-service container inside gateway pod
  enabled: true
  
  # -- Issuer Service image configuration (inherits global.image.registry and global.image.namespace)
  image:
    # registry: ""  # Uncomment to override global.image.registry
    # namespace: ""  # Uncomment to override global.image.namespace
    repository: gateway-issuer-service-go
    tag: "2.2.1"
  
  # -- Image pull policy for Issuer Service container
  imagePullPolicy: IfNotPresent

  # When providing an existing secret, it has to compatible with a gateway-rotator managed one
  # Format is specified here https://github.com/telekom/gateway-rotator?tab=readme-ov-file#key-rotation-process
  # -- configure manually externally managed secret for oauth (as alternative for keyRotation.enabled=true) 
  existingJwkSecretName:

  # -- issuerService livenessProbe configuration
  livenessProbe:
    httpGet:
      path: /health
      port: issuer-service
      scheme: HTTP
    timeoutSeconds: 5
    failureThreshold: 6
  # -- issuerService readinessProbe configuration
  readinessProbe:
    httpGet:
      path: /health
      port: issuer-service
      scheme: HTTP
  # -- issuerService startupProbe configuration
  startupProbe:
    httpGet:
      path: /health
      port: issuer-service
      scheme: HTTP
    periodSeconds: 1
    failureThreshold: 60

  # -- Container security context for Issuer Service
  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL

  # -- generic injection possibility for additional environment variables
  #- {name: foo, value: bar}
  environment: []

  # -- issuerService container default resource configuration
  resources:
    limits:
      cpu: 500m
      memory: 500Mi
    requests:
      cpu: 50m
      memory: 200Mi

circuitbreaker:
  # -- enable deployment of circuitbreaker component
  enabled: false
  
  # -- Circuitbreaker image configuration (inherits global.image.registry and global.image.namespace)
  image:
    # registry: ""  # Uncomment to override global.image.registry
    # namespace: ""  # Uncomment to override global.image.namespace
    repository: gateway-circuitbreaker
    tag: "2.1.0"
  
  # -- Image pull policy for Circuitbreaker container
  imagePullPolicy: IfNotPresent

  # -- Interval for circuitbreaker checks
  interval: 60s
  # -- Number of failures before triggering circuit breaker
  count: 4

  # -- Container security context for Circuitbreaker
  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL

  # -- circuitbreaker container default resource configuration
  resources:
    limits:
      cpu: 0.5
      memory: 500Mi
    requests:
      cpu: 50m
      memory: 200Mi

postgresql:
  # -- PostgresQL image configuration (inherits global.image.registry and global.image.namespace)
  image:
    # registry: ""  # Uncomment to override global.image.registry
    # namespace: ""  # Uncomment to override global.image.namespace
    repository: postgresql
    tag: "16.5"
  
  # -- Image pull policy for PostgreSQL container
  imagePullPolicy: IfNotPresent
  
  # -- Pod security context for PostgreSQL
  podSecurityContext:
    fsGroup: 999
    supplementalGroups: [999]
  
  # -- Container security context for PostgreSQL
  containerSecurityContext:
    runAsUser: 999
    runAsGroup: 999
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL
  
  # -- database admin credentials
  #adminPassword: "changeme"
  
  # -- maximum number of client connections
  maxConnections: "100"
  
  # -- memory dedicated to PostgreSQL for caching data
  sharedBuffers: "32MB"
  
  # -- maximum number of transactions that can be in the "prepared" state simultaneously
  # setting this parameter to zero (default) disables the prepared-transaction feature
  maxPreparedTransactions: "0"
  
  # -- postgresql container default resource configuration
  resources:
    limits:
      cpu: 100m
      memory: 500Mi
    requests:
      cpu: 20m
      memory: 200Mi
  
  persistence:
    keepOnDelete: false
    # -- Storage class name for PostgreSQL PVC (defaults to cluster default storage class if not set)
    #storageClassName: ""
    resources:
      requests:
        storage: 1Gi
    # -- Mount directory for PostgreSQL data
    mountDir: '/var/lib/postgresql/data'
  
  deployment:
    annotations: {}

externalDatabase: 
  # Set host if you use an external database or service name is not sufficient
  #host: 'some-external-postgresql-database.example.com'
  ssl: true
  sslVerify: false
  #luaSslTrustedCertificate: |
  #  -----BEGIN CERTIFICATE-----
  #  <CA certificate in PEM format here>
  #  -----END CERTIFICATE-----

# -- Job image configuration (inherits global.image.registry and global.image.namespace)
job:
  image:
    # registry: ""  # Uncomment to override global.image.registry
    # namespace: ""  # Uncomment to override global.image.namespace
    repository: bash-curl
    tag: "8.13.0"

# enabling keyRotration requires a working cert-manager as well as the gateway-rotator
# alternatively use jumper.existingJwkSecretName and issuerService.existingJwkSecretName to provide compatible secret
keyRotation:
  # -- enable automatic cert / key rotation for access token issueing based on cert-manager and gateway-rotator
  enabled: false
  # -- provide alternative configuration for cert-managers Certificate resource
  additionalSpecValues: {}
    #privateKey:
    #  rotationPolicy: Never
    #duration: 2160h
    #renewBefore: 360h
    #commonName: stargate.telekom.de
    #dnsNames:
    #  - stargate.telekom.de

pdb:
  # -- enable pod discruption budget creation
  create: false
  # -- minAvailable pods in number or percent
  minAvailable:
  # --  maxUnavailable pods in number or percent (defaults to 1 if unset and minAvailable also unset)
  maxUnavailable:

# ============================================================================
# Argo Rollouts Configuration
# ============================================================================
# Argo Rollouts provides advanced deployment capabilities with progressive 
# delivery strategies like canary and blue-green deployments.
#
# Prerequisites:
# - Argo Rollouts must be installed in the cluster
# - For metric-based analysis, a metrics provider (Prometheus/Victoria Metrics) must be accessible
#
# Note: argoRollouts is mutually exclusive with standard Deployment.
# When enabled, a Rollout resource replaces the Deployment using workloadRef.
# ============================================================================

argoRollouts:
  # -- Enable Argo Rollouts progressive delivery (replaces standard Deployment)
  enabled: false
  
  workloadRef:
    # -- scaleDown strategy for Argo Rollouts deployment workloadRef
    scaleDown: progressively
    # -- enable explicit downscale of old Deployment during first take over of pod responsibility through argo rollouts together with argocd (see README.md for details)
    explicitDownscale: false

  # ============================================================================
  # Rollout Strategy Configuration
  # ============================================================================
  strategy:
    # -- Deployment strategy type: "canary" or "blueGreen"
    type: canary
    
    # Canary strategy configuration
    canary:
      additionalProperties:
        # -- Maximum number of pods that can be unavailable during rollout (number or percentage)
        maxUnavailable: "50%"

        # -- Maximum number of extra pods that can be created during rollout (number or percentage)
        maxSurge: "25%"

        # -- Enable dynamic stable scale (mutual exclusive to scaleDownDelaySeconds )
        dynamicStableScale: true

      # ============================================================================
      # Canary Steps Configuration
      # ============================================================================
      # Define the progression of traffic shift during canary deployment
      # Each step can set weight, pause duration, or trigger analysis

      # -- Canary step definition with a weight of 10% and a pause of 5 minutes
      steps:
        - setWeight: 10
        - pause:
            duration: 1m
        - setWeight: 20
        - pause:
            duration: 1m
        - setWeight: 40
        - pause:
            duration: 1m
        - setWeight: 60
        - pause:
            duration: 1m            
        - setWeight: 80
        - pause:
            duration: 1m

      # ============================================================================
      # Analysis Configuration
      # ============================================================================
      # Optional background analysis that runs continuously during canary
      
      analysis:
        # -- AnalysisTemplate references for background analysis
        templates:
          - templateName: success-rate-analysis
        # -- Arguments to pass to the analysis template
        args: []
        # -- Canary step at which to start the analysis (1-based index)
        startingStep:

    # -- blueGreen strategy configuration (except activeService and previewService - these are handled by template)
    blueGreen:
      autoPromotionEnabled: false

  # ============================================================================
  # Analysis Templates Configuration
  # ============================================================================
  # Define metrics and success criteria for automated rollout validation
  
  analysisTemplates:
    # -- Enable creation of AnalysisTemplates
    enabled: true
    
    # ============================================================================
    # Error Rate Analysis Template
    # ============================================================================
    # Validates that error rate stays below acceptable threshold
    
    errorRate:
      # -- Enable error rate analysis
      enabled: false
      # -- Analysis interval (how often to check)
      interval: 30s
      # -- Number of measurements to take
      count: 0
      # -- Number of failed measurements that trigger rollback
      failureLimit: 2
      # -- Success criteria (PromQL query must return < threshold)
      successCondition: "all(result, # < 0.05)"
      # -- Error rate threshold (5% = 0.05)
      # PromQL query to calculate error rate over last 5 minutes
      query: |
        sum(irate(
        kong_http_requests_total{tardis_telekom_de_zone="{{ args.zone }}",namespace="{{ args.namespace }}",route=~"{{ args.route-regex }}",role="canary",code!~"5.."}[1m]
        )) /
        sum(irate(
        kong_http_requests_total{tardis_telekom_de_zone="{{ args.zone }}",namespace="{{ args.namespace }}",route=~"{{ args.route-regex }}",role="canary"}[1m]
        ))

      # -- Prometheus server address (must be accessible)
      # Example: "http://prometheus.monitoring.svc.cluster.local:8427"
      prometheusAddress: ""
      
      # -- Prometheus authentication using Basic Auth
      # Credentials are read from a Kubernetes secret in the same namespace
      authentication:
        # -- Enable authentication for Prometheus queries
        enabled: true
        
        # -- Secret name containing Prometheus credentials
        # This secret must exist in the same namespace as the Rollout
        # Example secret creation:
        #   apiVersion: v1
        #   kind: Secret
        #   metadata:
        #     name: victoria-metrics-secret
        #   type: Opaque
        #   stringData:
        #     username: "my-username"
        #     password: "my-password"
        secretName: "victoria-metrics-secret"
        
        # -- Secret key containing base64 encoded user:password combination to be used as Basic Auth header
        basicKey: "basic-auth"

    # ============================================================================
    # Success Rate Analysis Template
    # ============================================================================
    # Validates that success rate stays above acceptable threshold
    
    successRate:
      # -- Enable success rate analysis
      enabled: true
      # -- Analysis interval
      interval: 30s
      # -- Number of measurements to take
      count: 0
      # -- Number of failed measurements that trigger rollback
      failureLimit: 3
      # -- Success criteria (PromQL query must return > threshold)
      successCondition: "all(result, # >= 0.95)"
      # -- Success rate threshold (95% = 0.95)
      # PromQL query to calculate success rate over last 1 minute
      query: |
        sum(irate(
          kong_http_requests_total{tardis_telekom_de_zone="{{ args.zone }}",namespace="{{ args.namespace }}",route=~"{{ args.route-regex }}",role="canary",code!~"(4|5).*"}[1m]
        )) /
        sum(irate(
          kong_http_requests_total{tardis_telekom_de_zone="{{ args.zone }}",namespace="{{ args.namespace }}",route=~"{{ args.route-regex }}",role="canary"}[1m]
        ))

      # -- Prometheus server address
      prometheusAddress: ""
      
      # -- Prometheus authentication using Basic Auth
      # Credentials are read from a Kubernetes secret in the same namespace
      authentication:
        # -- Enable authentication for Prometheus queries
        enabled: true
        
        # -- Secret name containing Prometheus credentials
        secretName: "victoria-metrics-secret"
        
        # -- Secret key containing base64 encoded user:password combination to be used as Basic Auth header
        basicKey: "basic-auth"
