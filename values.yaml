# SPDX-FileCopyrightText: 2023 Deutsche Telekom AG
#
# SPDX-License-Identifier: Apache-2.0

global:
  # -- Zone identifier for the gateway instance (must match control plane configuration)
  zone: "default"
  # -- Environment name (e.g. playground, preprod, ...)
  environment: "default"

  # -- Path to secret (optional)
  #pathToSecret: "path/to/secret"

  # -- Storage class name for PVCs (uses cluster default if not set)
  #storageClassName: ""

  # -- Common labels applied to all Kubernetes resources (transferred to Prometheus metrics if ServiceMonitor is enabled)
  labels: {}

  ingress:
    # -- Default ingress class name for all ingress resources (uses cluster default if not set, can be overridden per component)
    #ingressClassName: ""
    # -- Common annotations for all ingress resources (can be extended per component)
    annotations: {}
      #external-dns.alpha.kubernetes.io/target: ""
      #kubernetes.io/ingress.class: ""

  # Default image configuration (can be overridden per component)
  # Images are constructed as: {registry}/{namespace}/{repository}:{tag}
  # Example: mtr.devops.telekom.de/eu_it_co_development/o28m/gateway-kong:1.1.0
  image:
    # -- Default image registry
    registry: mtr.devops.telekom.de
    # -- Default image namespace
    namespace: eu_it_co_development/o28m

  # -- Array of pull secret names for image pulling
  imagePullSecrets: []

  # -- Default image pull policy
  imagePullPolicy: IfNotPresent

  # Password generation rules
  passwordRules:
    # -- Enable password rule enforcement
    enabled: false
    # -- Minimum password length
    length: 12
    # -- Password must match these regex patterns
    mustMatch:
    - '[a-z]'
    - '[A-Z]'
    - '[0-9]'
    - '[^a-zA-Z0-9]'

  database:
    # -- Database location: 'local' (deploy with chart) or 'external' (provided externally)
    location: local
    # -- Database port
    port: 5432
    # -- Database name
    database: kong
    # -- Database schema
    schema: public
    # -- Database username
    username: kong
    # -- Database password
    password: changeme

  # Global tracing configuration (can be overridden per component)
  tracing:
    # -- Zipkin collector URL (e.g., Jaeger collector), must include http(s) scheme
    collectorUrl: "http://guardians-drax-collector.skoll:9411/api/v2/spans"
    # -- Service name displayed in tracing UI
    defaultServiceName: "stargate"
    # -- Sample ratio for requests without trace IDs (0=off, 1=all requests)
    sampleRatio: 1

  podAntiAffinity:
    # -- Use required (hard) or preferred (soft) pod anti-affinity
    required: false

  # -- Fail template rendering on unset required values
  failOnUnsetValues: true

  # -- Base sleep duration in seconds for pre-stop lifecycle hook
  preStopSleepBase: 30

# List template files that should trigger pod restart when changed
# Useful for ConfigMaps or Secrets that need immediate propagation
#templateChangeTriggers:
#- my-custom-configmap.yaml
# -- List of template files for which a checksum annotation will be created
templateChangeTriggers: []

# -- Kong Gateway image configuration (inherits from global.image)
image:
  # registry: ""  # Override global.image.registry
  # namespace: ""  # Override global.image.namespace
  repository: gateway-kong
  # -- Kong Gateway image tag
  tag: "1.3.0"

# -- Image pull policy for Kong container
imagePullPolicy: IfNotPresent

# Migration behavior: 'bootstrap' (new deployment), 'upgrade' (Kong version upgrade), 'jobs' (ENI plugin migration), or 'none'
# -- Migration mode for database initialization or upgrades
migrations: none


# Kong Admin API configuration
adminApi:
  # -- Create Service for Kong Admin API
  enabled: true
  # -- Admin API key for authentication
  gatewayAdminApiKey: changeme
  # -- Htpasswd for Admin API basic authentication
  htpasswd: admin:changeme
  tls:
    # -- Enable HTTPS for Admin API
    enabled: false
  # -- Access log target
  accessLog: /dev/stdout
  # -- Error log target
  errorLog: /dev/stderr
  ingress:
    # -- Enable ingress for Admin API
    enabled: true
    # -- Ingress class name for Admin API ingress (overrides global.ingress.ingressClassName)
    #className: ""
    # -- Ingress annotations (merged with global.ingress.annotations)
    annotations: {}
    # -- Ingress hosts configuration
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: Prefix
    tls: []
      # secretName is optional as for example in aws for a loadbalancer ingress this is not needed
      #- secretName: secretName
      #  hosts:
      #    - hostNameMatchingCertInSecret


# Kong Proxy configuration
proxy:
  tls:
    # -- Enable TLS for proxy
    enabled: false
  # -- Access log target
  accessLog: /dev/stdout
  # -- Error log target
  errorLog: /dev/stderr
  ingress:
    # -- Enable ingress for proxy
    enabled: true
    # -- Ingress class name for proxy route (overrides global.ingress.ingressClassName)
    #className: ""
    # -- Ingress annotations (merged with global.ingress.annotations)
    annotations: {}
    # -- Ingress hosts configuration
    hosts:
      - host: chart-example.local
        paths:
          - path: /
            pathType: Prefix
    # -- TLS configuration (secretName optional for cloud load balancers)
    tls: []
      #- secretName: secretName
      #  hosts:
      #    - hostNameMatchingCertInSecret

# -- Post-deployment configuration script (curl commands for Admin API)
#configuration: |
  #Place your curl commands for configuring the Admin API here

# SSL/TLS configuration
# -- Enable SSL certificate verification for upstream traffic
sslVerify: false
# -- SSL certificate verification depth
sslVerifyDepth: '1'

# -- CA certificates bundle in PEM format for SSL verification
#trustedCaCertificates: |
#  -----BEGIN CERTIFICATE-----
#  <CA certificate 01>
#  -----END CERTIFICATE-----
#  -----BEGIN CERTIFICATE-----
#  <CA certificate 02>
#  -----END CERTIFICATE-----

# -- Default HTTPS server certificate secret name (route-specific certificates can be configured at runtime)
#defaultTlsSecret: "mysecret"

# TLS protocol and cipher configuration
ssl:
  # -- Allowed TLS protocols
  protocols: "TLSv1.2 TLSv1.3"
  # -- TLS cipher suite: modern, intermediate, old, or custom (see https://wiki.mozilla.org/Security/Server_Side_TLS)
  cipherSuite: "custom"
  # -- Custom TLS ciphers (OpenSSL format, ignored unless cipherSuite is 'custom')
  ciphers: "DHE-DSS-AES128-SHA256:DHE-DSS-AES256-SHA256:DHE-DSS-AES128-GCM-SHA256:DHE-DSS-AES256-GCM-SHA384:DHE-RSA-AES128-CCM:DHE-RSA-AES256-CCM:DHE-RSA-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-RSA-AES128-GCM-SHA256:DHE-RSA-AES256-GCM-SHA384:DHE-RSA-CHACHA20-POLY1305:ECDHE-ECDSA-AES128-CCM:ECDHE-ECDSA-AES256-CCM:ECDHE-ECDSA-AES128-SHA256:ECDHE-ECDSA-AES256-SHA384:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-ECDSA-CHACHA20-POLY1305:ECDHE-RSA-AES128-SHA256:ECDHE-RSA-AES256-SHA384:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-RSA-CHACHA20-POLY1305:TLS_AES_256_GCM_SHA384:TLS_CHACHA20_POLY1305_SHA256:TLS_AES_128_GCM_SHA256:TLS_AES_128_CCM_SHA256"

# -- Disable upstream response caching
disableUpstreamCache: false

# -- Pod security context for Kong deployment (hardened defaults)
podSecurityContext:
  runAsUser: 100
  runAsGroup: 1000
  fsGroup: 1000
  supplementalGroups: [1000]

# -- Container security context for Kong container (hardened defaults)
containerSecurityContext:
  runAsUser: 100
  runAsGroup: 1000
  runAsNonRoot: true
  readOnlyRootFilesystem: true
  allowPrivilegeEscalation: false
  privileged: false
  capabilities:
    drop:
    - ALL

# -- Topology key for pod anti-affinity (spread pods across zones for high availability)
topologyKey: kubernetes.io/hostname

# Job security configuration
jobs:
  # -- Container security context for setup jobs
  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL

# -- Kong memory cache size for database entities
memCacheSize: 128m
# -- Number of nginx worker processes
nginxWorkerProcesses: 4
# -- Nginx HTTP Lua shared dictionary for storing metrics
nginxHttpLuaSharedDict: "prometheus_metrics 15m"
# -- Nginx large client header buffers configuration
#nginxLargeClientBuffers: "8 16k"
# -- Kong worker consistency mode (eventual or strict)
workerConsistency: eventual
# -- Frequency in seconds to poll for worker state updates
workerStateUpdateFrequency: 10
# -- Frequency in seconds to poll database for updates
dbUpdateFrequency: 10
# -- Delay in seconds before propagating database updates
dbUpdatePropagation: 0
# -- HTTP client body buffer size (optional override)
#httpClientBodyBufferSize: 4m
# -- Trusted IPs for real IP detection (optional override)
#trustedIps: 100.70.0.0/16
# -- Header to use for real IP detection (optional override)
#realIpHeader: x-original-forwarded-for
# -- Whether to recursively search for client IP (optional override)
#realIpRecursive: OFF

# -- Number of Kong pod replicas (ignored when HPA, KEDA, or Argo Rollouts is enabled)
replicas: 1

# -- Deployment strategy configuration
strategy:
  type: RollingUpdate
  rollingUpdate:
    maxUnavailable: 25%
    maxSurge: 25%

# -- Horizontal Pod Autoscaler configuration
hpaAutoscaling:
  enabled: false
  # -- Minimum number of replicas
  minReplicas: 3
  # -- Maximum number of replicas
  maxReplicas: 10
  # -- Target CPU utilization percentage
  cpuUtilizationPercentage: 80

# ============================================================================
# KEDA-Based Autoscaling Configuration
# ============================================================================
# KEDA (Kubernetes Event-Driven Autoscaling) provides advanced autoscaling
# capabilities including custom metrics, schedule-based scaling, and
# sophisticated anti-flapping protection.
#
# Prerequisites:
# - KEDA must be installed in the cluster (helm install keda kedacore/keda)
# - Victoria Metrics must be accessible for custom metric scaling
# - Kubernetes metrics server must be running for CPU/memory scaling
#
# Note: kedaAutoscaling and autoscaling (HPA) are mutually exclusive.
# Enable only one at a time.
# ============================================================================

kedaAutoscaling:
  # -- Enable KEDA-based autoscaling (disables standard HPA if enabled)
  enabled: false
  
  # ============================================================================
  # Replica Boundaries
  # ============================================================================
  
  # -- Minimum number of replicas (must be >= 1)
  minReplicas: 2
  
  # -- Maximum number of replicas (must be >= minReplicas)
  maxReplicas: 10
  
  # ============================================================================
  # Timing Configuration (Anti-Flapping)
  # ============================================================================
  
  # -- Polling interval in seconds (how often KEDA checks metrics)
  # Lower values = more responsive but more API calls
  # Recommended: 30-60 seconds for balanced behavior
  pollingInterval: 30
  
  # -- Cooldown period in seconds (minimum time between scale-down actions)
  # Prevents rapid scale-down oscillations
  # Recommended: 300 seconds (5 minutes) for stable workloads
  cooldownPeriod: 300
  
  # ============================================================================
  # Fallback Configuration
  # ============================================================================
  # Defines behavior when all scaling triggers fail (e.g., metrics unavailable)
  
  fallback:
    # -- Enable fallback to a fixed replica count when all triggers fail
    enabled: false
    
    # -- Number of replicas to maintain when all triggers fail (e.g. maxReplicas)
    replicas: 10
  
  # ============================================================================
  # Advanced HPA Behavior Configuration
  # ============================================================================
  # Fine-tune scaling behavior using Kubernetes HPA v2 behavior policies
  
  advanced:
    # -- Restore to original replica count when ScaledObject is deleted
    restoreToOriginalReplicaCount: false
    
    # -- HPA behavior configuration (scale-up/scale-down policies)
    horizontalPodAutoscalerConfig:
      # -- Scaling behavior policies
      behavior:
        # -- Scale-down behavior (conservative to prevent flapping)
        scaleDown:
          # -- Stabilization window for scale-down in seconds (KEDA waits before scaling down)
          stabilizationWindowSeconds: 300
          
          # -- Scale-down policies (multiple policies can be defined)
          policies:
          - type: Percent
            value: 10        # Max 10% reduction per period
            periodSeconds: 60
          
          # -- Policy selection (Min = most conservative, Max = most aggressive)
          selectPolicy: Min
        
        # -- Scale-up behavior (aggressive for availability)
        scaleUp:
          # -- Stabilization window for scale-up in seconds (0 = immediate scale-up)
          stabilizationWindowSeconds: 0
          
          # -- Scale-up policies
          policies:
          - type: Percent
            value: 100       # Max 100% increase per period
            periodSeconds: 60
          - type: Pods
            value: 4         # Or max 4 pods per period
            periodSeconds: 60
          
          # -- Policy selection (Max = use most aggressive policy)
          selectPolicy: Max
  
  # ============================================================================
  # Scaling Triggers
  # ============================================================================
  # Multiple triggers can be enabled simultaneously (OR logic)
  # If ANY trigger suggests scale-up → scale up
  # If ALL triggers suggest scale-down → scale down (after cooldown)
  
  triggers:
    
    # ==========================================================================
    # CPU Resource Scalers (Per-Container)
    # ==========================================================================
    # Scales based on CPU utilization percentage for individual containers
    # Requires: Kubernetes metrics server
    # Multiple containers can be monitored independently
    
    cpu:
      # -- Enable CPU-based scaling for any container
      enabled: true
      
      # -- Per-container CPU thresholds (any container exceeding threshold triggers scaling)
      containers:
        # -- Kong container CPU scaling configuration
        kong:
          # -- Enable CPU monitoring for Kong container
          enabled: true
          # -- CPU utilization threshold percentage (0-100, recommended: 60-80% for headroom)
          threshold: 70
        
        # -- Jumper container CPU scaling configuration
        jumper:
          # -- Enable CPU monitoring for Jumper container
          enabled: true
          # -- CPU utilization threshold percentage (0-100)
          threshold: 70
        
        # -- Issuer Service container CPU scaling configuration
        issuerService:
          # -- Enable CPU monitoring for Issuer Service container
          enabled: true
          # -- CPU utilization threshold percentage (0-100)
          threshold: 70
    
    # ==========================================================================
    # Memory Resource Scalers (Per-Container)
    # ==========================================================================
    # Scales based on memory utilization percentage for individual containers
    # Requires: Kubernetes metrics server
    # Multiple containers can be monitored independently
    
    memory:
      # -- Enable memory-based scaling for any container
      enabled: true
      
      # -- Per-container memory thresholds (any container exceeding threshold triggers scaling)
      containers:
        # -- Kong container memory scaling configuration
        kong:
          # -- Enable memory monitoring for Kong container
          enabled: true
          # -- Memory utilization threshold percentage (0-100, recommended: 80-90%)
          threshold: 95
        
        # -- Jumper container memory scaling configuration
        jumper:
          # -- Enable memory monitoring for Jumper container
          enabled: true
          # -- Memory utilization threshold percentage (0-100)
          threshold: 85
        
        # -- Issuer Service container memory scaling configuration
        issuerService:
          # -- Enable memory monitoring for Issuer Service container
          enabled: true
          # -- Memory utilization threshold percentage (0-100)
          threshold: 85
    
    # ==========================================================================
    # Prometheus/Victoria Metrics Scaler
    # ==========================================================================
    # Scales based on custom metrics from Victoria Metrics
    # Requires: Victoria Metrics accessible, authentication configured
    
    prometheus:
      # -- Enable Prometheus/Victoria Metrics based scaling
      enabled: true
      
      # -- Victoria Metrics server address (REQUIRED if enabled)
      # Example: "http://prometheus.monitoring.svc.cluster.local:8427"
      # Can use template variables: "{{ .Values.global.vmauth.url }}"
      serverAddress: ""
      
      # -- Metric name (used for identification in KEDA)
      metricName: "kong_request_rate"
      
      # -- PromQL query to execute
      # Must return a single numeric value
      # Can use Helm template variables (e.g., {{ .Values.global.zone }})
      # Example queries:
      #   - Request rate: sum(rate(kong_http_requests_total{zone="zone1"}[1m]))
      #   - Error rate: sum(rate(kong_http_requests_total{status=~"5.."}[1m]))
      query: 'sum(rate(kong_http_requests_total{ei_telekom_de_zone="{{ .Values.global.zone }}",ei_telekom_de_environment="{{ .Values.global.environment }}",app_kubernetes_io_instance="{{ .Release.Name }}-kong"}[1m]))'
      
      # -- Threshold value for the metric
      # Scales up when query result exceeds this value
      # For request rate: total requests/second across all pods
      threshold: "100"
      
      # -- Activation threshold (optional)
      # Minimum metric value to activate this scaler
      # Prevents scaling from 0 on minimal load
      activationThreshold: ""
      
      # -- Authentication mode for Victoria Metrics
      # Options: "basic", "bearer", "tls"
      authModes: "basic"
      
      # -- KEDA authentication configuration for Victoria Metrics access
      # Reference to existing TriggerAuthentication or ClusterTriggerAuthentication resource
      authentication:
        # -- Authentication kind: "ClusterTriggerAuthentication" or "TriggerAuthentication"
        # Use "TriggerAuthentication" for namespace-scoped environments
        # Use "ClusterTriggerAuthentication" for cluster-wide shared credentials
        kind: "ClusterTriggerAuthentication"
        
        # -- Name of the TriggerAuthentication or ClusterTriggerAuthentication resource
        # This resource must be created separately and contain Victoria Metrics credentials
        # Example ClusterTriggerAuthentication:
        #   apiVersion: keda.sh/v1alpha1
        #   kind: ClusterTriggerAuthentication
        #   metadata:
        #     name: eni-keda-vmselect-creds
        #   spec:
        #     secretTargetRef:
        #     - parameter: username
        #       name: victoria-metrics-secret
        #       key: username
        #     - parameter: password
        #       name: victoria-metrics-secret
        #       key: password
        #
        # Example TriggerAuthentication (namespace-scoped):
        #   apiVersion: keda.sh/v1alpha1
        #   kind: TriggerAuthentication
        #   metadata:
        #     name: vmselect-creds
        #     namespace: my-namespace
        #   spec:
        #     secretTargetRef:
        #     - parameter: username
        #       name: victoria-metrics-secret
        #       key: username
        #     - parameter: password
        #       name: victoria-metrics-secret
        #       key: password
        name: "eni-keda-vmselect-creds"
    
    # ==========================================================================
    # Cron-Based Scalers
    # ==========================================================================
    # Scales based on time schedules (predictable traffic patterns)
    # Multiple schedules can be defined for different time windows
    
    cron:
      # -- Enable cron-based (schedule) scaling
      enabled: false
      
      # -- Timezone for cron schedules
      # Use IANA timezone database names for automatic DST handling
      # Europe/Berlin automatically handles CET (UTC+1) and CEST (UTC+2) transitions
      # Format: IANA timezone (e.g., "Europe/Berlin", "America/New_York", "Asia/Tokyo")
      # See: https://en.wikipedia.org/wiki/List_of_tz_database_time_zones
      timezone: "Europe/Berlin"
      
      # -- Cron schedule definitions (time windows with desired replica counts)
      # Each schedule defines start/end times and replica count
      # Multiple schedules can overlap (highest desiredReplicas wins)
      schedules: []
      # Example schedules:
      # - name: "business-hours-scale-up"
      #   start: "0 8 * * 1-5"      # 8 AM Monday-Friday
      #   end: "0 18 * * 1-5"       # 6 PM Monday-Friday
      #   desiredReplicas: 5
      # 
      # - name: "weekend-scale-down"
      #   start: "0 0 * * 6-7"      # Midnight Saturday-Sunday
      #   end: "0 23 * * 6-7"       # 11 PM Saturday-Sunday
      #   desiredReplicas: 2
      #
      # - name: "night-scale-down"
      #   start: "0 22 * * *"       # 10 PM every day
      #   end: "0 6 * * *"          # 6 AM every day
      #   desiredReplicas: 2
      #
      # Cron expression format:
      # ┌───────────── minute (0 - 59)
      # │ ┌───────────── hour (0 - 23)
      # │ │ ┌───────────── day of month (1 - 31)
      # │ │ │ ┌───────────── month (1 - 12)
      # │ │ │ │ ┌───────────── day of week (0 - 6) (Sunday to Saturday)
      # │ │ │ │ │
      # * * * * *

# -- Kong container resource limits and requests
resources:
  requests:
    cpu: 1500m
    memory: 3Gi
  limits:
    cpu: 2500m
    memory: 4Gi

# -- Nginx log format: debug, default, json, or plain
logFormat: json

# -- Kong liveness probe configuration
livenessProbe:
  httpGet:
    path: /status
    port: status
    scheme: HTTP
  timeoutSeconds: 5
  periodSeconds: 20
  failureThreshold: 4
# -- Kong readiness probe configuration
readinessProbe:
  httpGet:
    path: /status
    port: status
    scheme: HTTP
  timeoutSeconds: 2
# -- Kong startup probe configuration
startupProbe:
  httpGet:
    path: /status
    port: status
    scheme: HTTP
  initialDelaySeconds: 5
  timeoutSeconds: 1
  periodSeconds: 1
  failureThreshold: 295

# Setup jobs configuration
setupJobs:
  # -- Maximum number of retries for failed jobs
  backoffLimit: 15
  # -- Maximum job duration in seconds
  activeDeadlineSeconds: 3600
  # -- Resource limits and requests for setup jobs
  resources:
    requests:
      cpu: 50m
      memory: 200Mi
    limits:
      cpu: 500m
      memory: 500Mi
  # -- Container security context for setup jobs
  containerSecurityContext:
    runAsUser: 100
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL

# Kong plugin configuration
plugins:
  # -- Container security context for plugin containers
  containerSecurityContext:
    runAsUser: 100
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL
  # -- Additional Kong plugins to enable (beyond bundled and jwt-keycloak)
  enabled:
    - rate-limiting-merged

  acl:
    # -- Plugin ID for Kong configuration
    pluginId: bc823d55-83b5-4184-b03f-ce63cd3b75c7
      
  jwtKeycloak:
    # -- Enable JWT Keycloak plugin
    enabled: true
    # -- Plugin ID for Kong configuration
    pluginId: b864d58b-7183-4889-8b32-0b92d6c4d513
    # -- Allowed identity provider issuer URLs (used for authenticating Admin API requests from the Rover realm)
    allowedIss: 
      - https://<your-iris-host>/auth/realms/rover

  prometheus:
    # -- Enable Prometheus metrics plugin
    enabled: true
    # -- Plugin ID for Kong configuration
    pluginId: 3d232d3c-dc2b-4705-aa8d-4e07c4e0ff4c
    # -- Metrics endpoint port
    port: 9542
    # -- Metrics endpoint path
    path: /metrics
    serviceMonitor:
      # -- Enable ServiceMonitor for Prometheus Operator
      enabled: true
      # -- Can be used to manipulate metric labels at scrape time
      metricRelabelings: []
      # -- ServiceMonitor selector label
      selector: "guardians-raccoon"
      # -- HTTP scheme for scraping
      #scheme: http
      # -- Scrape interval
      #interval: "15s"
      # -- Scrape timeout
      #scrapeTimeout: "3s"
      # -- Honor labels on metric collision with target labels
      # honorLabels: true
    podMonitor:
      # -- Enable PodMonitor for Prometheus Operator
      enabled: false
      # -- Can be used to manipulate metric labels at scrape time
      metricRelabelings: []
      # -- PodMonitor selector label
      selector: "guardians-raccoon"
      # -- HTTP scheme for scraping
      # scheme: http
      # -- Scrape interval
      #interval: "15s"
      # -- Scrape timeout
      #scrapeTimeout: "3s"
      # -- Honor labels on metric collision with target labels
      #honorLabels: true

  requestSizeLimiting:
    # -- Enable request size limiting plugin
    enabled: true
    # -- Plugin ID for Kong configuration
    pluginId: 1e199eee-f592-4afa-8371-6b61dcbd1904
    # -- Maximum allowed payload size in megabytes
    #allowedPayloadSize: 4

  requestTransformer:
    # -- Plugin ID for Kong configuration
    pluginId: e9fb4272-0aff-4208-9efa-6bfec5d9df53

  zipkin:
    # -- Enable distributed tracing via ENI Zipkin plugin
    enabled: true
    # -- Plugin ID for Kong configuration
    pluginId: e8ff1211-816f-4d93-9011-a4b194586073
    # -- Zipkin collector URL (defaults to global.tracing.collectorUrl, must include http(s) scheme)
    #collectorUrl: "http://guardians-drax-collector.skoll:9411/api/v2/spans"
    # -- Sample ratio for requests without trace IDs (0=off, 1=all requests)
    #sampleRatio: 1
    # -- Environment name for traces
    #environment: null
    # -- Zone name for traces
    #zone: null
    # -- Force sampling for all requests
    #forceSample: true
    # -- Trace header type (b3 or w3c)
    #headerType: "b3"
    # -- Include consumer credentials in trace metadata
    #includeCredential: "true"
    # -- Service name displayed in tracing UI
    #defaultServiceName: "stargate"
    # -- CA certificate for Zipkin collector SSL verification
    #luaSslTrustedCertificate: |
    #  -----BEGIN CERTIFICATE-----
    #  <CA certificate in PEM format>
    #  -----END CERTIFICATE-----

# IRIX Broker route configuration (proxy route to IRIX broker service)
irixBrokerRoute:
  # -- Enable IRIX broker route
  enabled: false
  # -- Route name
  name: user-login
  # -- Route hostname (optional, uses default host rules if not set)
  #host: integration.spacegate.telekom.de
  upstream:
    # -- Upstream protocol
    protocol: http
    # -- Upstream service name
    service: irix-broker
    # -- Upstream service path
    path: /auth/realms/eni-login
    # -- Upstream service port
    port: 80
    # -- Upstream hostname (optional, for ingress access)
    #host: integration.spacegate.telekom.de
    # -- Upstream service namespace (optional, for cross-namespace access)
    #namespace: integration

# Jumper component for Gateway-to-Gateway communication and Last Mile Security
jumper:
  # -- Enable Jumper container deployment
  enabled: true
  
  # -- Jumper image configuration (inherits from global.image)
  image:
    # registry: ""  # Override global.image.registry
    # namespace: ""  # Override global.image.namespace
    repository: gateway-jumper
    tag: "4.4.0"
  
  # -- Image pull policy for Jumper container
  imagePullPolicy: IfNotPresent
  
  # -- Jumper container port
  port: 8080
  
  # -- Issuer service URL for gateway token issuance (your gateway's auth realm endpoint)
  issuerUrl: https://<your-gateway-host>/auth/realms/default
  # -- Tracing collector URL (optional)
  #tracingUrl: http://guardians-drax-collector.skoll:9411
  # -- Service name for tracing (optional)
  #defaultServiceName: "stargate"
  # -- Gateway URL for Gateway-to-Gateway communication
  stargateUrl: https://<your-gateway-host>
  # -- Event publisher URL
  publishEventUrl: http://producer.integration:8080/v1/events
  # -- JVM options for Jumper
  jvmOpts: "-XX:MaxRAMPercentage=75.0 -Dreactor.netty.pool.leasingStrategy=lifo"
  #maxHttpHeaderSize: 16KB
  #fpaProxyHost
  #fpaProxyPort
  #fpaNonProxyHostsRegex
  # -- Jumper liveness probe configuration
  livenessProbe:
    httpGet:
      path: /actuator/health/liveness
      port: jumper
      scheme: HTTP
    timeoutSeconds: 5
    failureThreshold: 6
  # -- Jumper readiness probe configuration
  readinessProbe:
    httpGet:
      path: /actuator/health/readiness
      port: jumper
      scheme: HTTP
    initialDelaySeconds: 5
  # -- Jumper startup probe configuration
  startupProbe:
    httpGet:
      path: /actuator/health/readiness
      port: jumper
      scheme: HTTP
    initialDelaySeconds: 15
    periodSeconds: 1
    failureThreshold: 285

  # -- Additional environment variables for Jumper container
  #- {name: foo, value: bar}
  environment: []

  # -- Container security context for Jumper
  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL
  # Zone health monitoring configuration (requires Redis)
  zoneHealth:
    # -- Default health status when Redis is unavailable
    defaultHealth: true
    # -- Redis database hostname
    databaseHost: localhost
    # -- Redis connection timeout in milliseconds
    databaseConnectionTimeout: 500
    # -- Redis operation timeout in milliseconds
    databaseTimeout: 500
    # -- Redis database port
    databasePort: 6379
    # -- Redis database index
    databaseIndex: 2
    # -- Redis Pub/Sub channel for zone status
    keyChannel: stargate-zone-status
    # -- Maximum request rate per second
    requestRate: 10000
    # -- Secret name containing Redis credentials
    databaseSecretName: redis
    # -- Secret key for Redis password
    databaseSecretKey: redis-password
    # -- Enable zone health monitoring
    enabled: false

  # -- List of zones that are considered internet-facing (empty list uses Jumper's default configuration)
  # Example: [space, canis, aries]
  internetFacingZones: []

  # -- Existing JWK secret name for OAuth token issuance (alternative to keyRotation.enabled=true)
  # Must be compatible with gateway-rotator format: https://github.com/telekom/gateway-rotator#key-rotation-process
  existingJwkSecretName:

  # -- Jumper container resource limits and requests
  resources:
    requests:
      cpu: 1500m
      memory: 1Gi
    limits:
      cpu: 5000m
      memory: 1Gi

# Issuer Service component for OAuth token generation
issuerService:
  # -- Enable Issuer Service container deployment
  enabled: true
  
  # -- Issuer Service image configuration (inherits from global.image)
  image:
    # registry: ""  # Override global.image.registry
    # namespace: ""  # Override global.image.namespace
    repository: gateway-issuer-service-go
    tag: "2.2.1"
  
  # -- Image pull policy for Issuer Service container
  imagePullPolicy: IfNotPresent

  # -- Existing JWK secret name for OAuth token signing (alternative to keyRotation.enabled=true)
  # Must be compatible with gateway-rotator format: https://github.com/telekom/gateway-rotator#key-rotation-process
  existingJwkSecretName:

  # -- Issuer Service liveness probe configuration
  livenessProbe:
    httpGet:
      path: /health
      port: issuer-service
      scheme: HTTP
    timeoutSeconds: 5
    failureThreshold: 6
  # -- Issuer Service readiness probe configuration
  readinessProbe:
    httpGet:
      path: /health
      port: issuer-service
      scheme: HTTP
  # -- Issuer Service startup probe configuration
  startupProbe:
    httpGet:
      path: /health
      port: issuer-service
      scheme: HTTP
    periodSeconds: 1
    failureThreshold: 60

  # -- Container security context for Issuer Service
  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL

  # -- Additional environment variables for Issuer Service container
  #- {name: foo, value: bar}
  environment: []

  # -- Issuer Service container resource limits and requests
  resources:
    requests:
      cpu: 50m
      memory: 10Mi
    limits:
      cpu: 500m
      memory: 50Mi

# Circuit breaker component configuration
circuitbreaker:
  # -- Enable circuit breaker component deployment
  enabled: false
  
  # -- Circuit breaker image configuration (inherits from global.image)
  image:
    # registry: ""  # Override global.image.registry
    # namespace: ""  # Override global.image.namespace
    repository: gateway-circuitbreaker
    tag: "2.1.0"
  
  # -- Image pull policy for circuit breaker container
  imagePullPolicy: IfNotPresent

  # -- Check interval for circuit breaker
  interval: 60s
  # -- Failure count threshold for circuit breaker activation
  count: 4

  # -- Container security context for circuit breaker
  containerSecurityContext:
    runAsUser: 1000
    runAsGroup: 1000
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL

  # -- Circuit breaker container resource limits and requests
  resources:
    requests:
      cpu: 50m
      memory: 200Mi
    limits:
      cpu: 500m
      memory: 500Mi

# PostgreSQL database configuration
postgresql:
  # -- PostgreSQL image configuration (inherits from global.image)
  image:
    # registry: ""  # Override global.image.registry
    # namespace: ""  # Override global.image.namespace
    repository: postgresql
    tag: "16.5"
  
  # -- Image pull policy for PostgreSQL container
  imagePullPolicy: IfNotPresent
  
  # -- Pod security context for PostgreSQL
  podSecurityContext:
    fsGroup: 999
    supplementalGroups: [999]
  
  # -- Container security context for PostgreSQL
  containerSecurityContext:
    runAsUser: 999
    runAsGroup: 999
    runAsNonRoot: true
    readOnlyRootFilesystem: true
    allowPrivilegeEscalation: false
    privileged: false
    capabilities:
      drop:
      - ALL
  
  # -- Database admin password
  #adminPassword: "changeme"
  
  # -- Maximum number of client connections
  maxConnections: "100"
  
  # -- Shared memory buffer size for data caching
  sharedBuffers: "32MB"
  
  # -- Maximum prepared transactions (0 disables prepared transactions)
  maxPreparedTransactions: "0"
  
  # -- PostgreSQL container resource limits and requests
  resources:
    requests:
      cpu: 20m
      memory: 200Mi
    limits:
      cpu: 100m
      memory: 500Mi
  
  persistence:
    # -- Keep PVC on chart deletion
    keepOnDelete: false
    # -- Storage class name (uses cluster default if not set)
    #storageClassName: ""
    # -- Storage resource requests
    resources:
      requests:
        storage: 1Gi
    # -- Data directory mount path
    mountDir: '/var/lib/postgresql/data'
  
  # -- Additional deployment annotations
  deployment:
    annotations: {}

# External database configuration
externalDatabase:
  # -- External database hostname
  #host: 'some-external-postgresql-database.example.com'
  # -- Enable SSL for external database connections
  ssl: true
  # -- Verify SSL certificates for external database
  sslVerify: false
  # -- Trusted CA certificate for SSL verification
  #luaSslTrustedCertificate: |
  #  -----BEGIN CERTIFICATE-----
  #  <CA certificate in PEM format>
  #  -----END CERTIFICATE-----

# -- Job image configuration for setup jobs (inherits from global.image)
job:
  image:
    # registry: ""  # Override global.image.registry
    # namespace: ""  # Override global.image.namespace
    repository: bash-curl
    tag: "8.13.0"

# Automatic certificate/key rotation (requires cert-manager and gateway-rotator)
# Alternative: use jumper.existingJwkSecretName and issuerService.existingJwkSecretName
keyRotation:
  # -- Enable automatic certificate/key rotation for OAuth token signing
  enabled: false
  # -- Additional Certificate resource configuration for cert-manager
  additionalSpecValues: {}
    #privateKey:
    #  rotationPolicy: Never
    #duration: 2160h
    #renewBefore: 360h
    #commonName: stargate.telekom.de
    #dnsNames:
    #  - stargate.telekom.de

# Pod Disruption Budget configuration
pdb:
  # -- Enable PodDisruptionBudget creation
  create: false
  # -- Minimum available pods (number or percentage)
  minAvailable:
  # -- Maximum unavailable pods (number or percentage, defaults to 1 if both unset)
  maxUnavailable:

# ============================================================================
# Argo Rollouts Configuration
# ============================================================================
# Argo Rollouts provides advanced deployment capabilities with progressive 
# delivery strategies like canary and blue-green deployments.
#
# Prerequisites:
# - Argo Rollouts must be installed in the cluster
# - For metric-based analysis, a metrics provider (Prometheus/Victoria Metrics) must be accessible
#
# Note: argoRollouts is mutually exclusive with standard Deployment.
# When enabled, a Rollout resource replaces the Deployment using workloadRef.
# ============================================================================

argoRollouts:
  # -- Enable Argo Rollouts progressive delivery (replaces standard Deployment)
  enabled: false
  
  workloadRef:
    # -- Scale-down strategy for workloadRef (progressively or immediately)
    scaleDown: progressively
    # -- Enable explicit downscale of old Deployment during initial Argo Rollouts takeover with ArgoCD (see README.md)
    explicitDownscale: false

  # ============================================================================
  # Rollout Strategy Configuration
  # ============================================================================
  strategy:
    # -- Deployment strategy type: "canary" or "blueGreen"
    type: canary
    
    # -- Canary strategy configuration
    canary:
      # -- Additional canary deployment properties
      additionalProperties:
        # -- Maximum unavailable pods during rollout (number or percentage)
        maxUnavailable: "50%"

        # -- Maximum surge pods during rollout (number or percentage)
        maxSurge: "25%"

        # -- Enable dynamic stable scaling (mutually exclusive with scaleDownDelaySeconds)
        dynamicStableScale: true

      # ============================================================================
      # Canary Steps Configuration
      # ============================================================================
      # Define traffic shift progression during canary deployment

      # -- Canary deployment steps (set weight percentages and pause durations)
      steps:
        - setWeight: 10
        - pause:
            duration: 1m
        - setWeight: 20
        - pause:
            duration: 1m
        - setWeight: 40
        - pause:
            duration: 1m
        - setWeight: 60
        - pause:
            duration: 1m            
        - setWeight: 80
        - pause:
            duration: 1m

      # ============================================================================
      # Analysis Configuration
      # ============================================================================
      # Optional background analysis during canary deployment
      
      # -- Background analysis configuration
      analysis:
        # -- AnalysisTemplate names for background analysis
        templates:
          - templateName: success-rate-analysis
        # -- Arguments passed to analysis templates
        args: []
        # -- Canary step number to start analysis (1-based index)
        startingStep:

    # -- Blue-Green strategy configuration (activeService and previewService handled by template)
    blueGreen:
      # -- Enable automatic promotion to new version
      autoPromotionEnabled: false

  # ============================================================================
  # Analysis Templates Configuration
  # ============================================================================
  # Define metrics and success criteria for automated rollout validation
  
  analysisTemplates:
    # -- Enable creation of AnalysisTemplates
    enabled: true
    
    # ============================================================================
    # Error Rate Analysis Template
    # ============================================================================
    # Validates that error rate stays below acceptable threshold
    
    errorRate:
      # -- Enable error rate analysis
      enabled: false
      # -- Analysis interval (how often to check)
      interval: 30s
      # -- Number of measurements to take
      count: 0
      # -- Number of failed measurements that trigger rollback
      failureLimit: 2
      # -- Success criteria (PromQL query must return < threshold)
      successCondition: "all(result, # < 0.05)"
      # -- Error rate threshold (5% = 0.05)
      # PromQL query to calculate error rate over last 5 minutes
      query: |
        sum(irate(
        kong_http_requests_total{ei_telekom_de_zone="{{ args.zone }}",ei_telekom_de_environment="{{ args.environment }}",app_kubernetes_io_instance="{{ args.instance }}",route=~"{{ args.route-regex }}",role="canary",code!~"5.."}[1m]
        )) /
        sum(irate(
        kong_http_requests_total{ei_telekom_de_zone="{{ args.zone }}",ei_telekom_de_environment="{{ args.environment }}",app_kubernetes_io_instance="{{ args.instance }}",route=~"{{ args.route-regex }}",role="canary"}[1m]
        ))

      # -- Prometheus server address (must be accessible)
      # Example: "http://prometheus.monitoring.svc.cluster.local:8427"
      prometheusAddress: ""
      
      # -- Prometheus Basic Auth authentication configuration
      authentication:
        # -- Enable authentication for Prometheus queries
        enabled: true
        
        # -- Secret name containing Prometheus credentials (must exist in same namespace as Rollout)
        # Example secret:
        #   apiVersion: v1
        #   kind: Secret
        #   metadata:
        #     name: victoria-metrics-secret
        #   type: Opaque
        #   stringData:
        #     username: "my-username"
        #     password: "my-password"
        secretName: "victoria-metrics-secret"
        
        # -- Secret key for base64 encoded user:password Basic Auth header
        basicKey: "basic-auth"

    # ============================================================================
    # Success Rate Analysis Template
    # ============================================================================
    # Validates that success rate stays above acceptable threshold
    
    successRate:
      # -- Enable success rate analysis
      enabled: true
      # -- Analysis interval
      interval: 30s
      # -- Number of measurements to take
      count: 0
      # -- Number of failed measurements that trigger rollback
      failureLimit: 3
      # -- Success criteria (PromQL query must return > threshold)
      successCondition: "all(result, # >= 0.95)"
      # -- Success rate threshold (95% = 0.95)
      # PromQL query to calculate success rate over last 1 minute
      query: |
        sum(irate(
          kong_http_requests_total{ei_telekom_de_zone="{{ args.zone }}",ei_telekom_de_environment="{{ args.environment }}",app_kubernetes_io_instance="{{ args.instance }}",route=~"{{ args.route-regex }}",role="canary",code!~"(4|5).*"}[1m]
        )) /
        sum(irate(
          kong_http_requests_total{ei_telekom_de_zone="{{ args.zone }}",ei_telekom_de_environment="{{ args.environment }}",app_kubernetes_io_instance="{{ args.instance }}",route=~"{{ args.route-regex }}",role="canary"}[1m]
        ))

      # -- Prometheus server address
      prometheusAddress: ""
      
      # -- Prometheus Basic Auth authentication configuration
      authentication:
        # -- Enable authentication for Prometheus queries
        enabled: true
        
        # -- Secret name containing Prometheus credentials
        secretName: "victoria-metrics-secret"
        
        # -- Secret key for base64 encoded user:password Basic Auth header
        basicKey: "basic-auth"
